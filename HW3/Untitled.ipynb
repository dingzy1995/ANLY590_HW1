{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model\n",
    "from keras import models\n",
    "from keras import backend as K\n",
    "from keras import layers\n",
    "from keras.utils import to_categorical\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "\n",
    "x = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))  # adapt this if using `channels_first` image data format\n",
    "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))  # adapt this if using `channels_first` image data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.2063 - val_loss: 0.1604\n",
      "Epoch 2/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1500 - val_loss: 0.1416\n",
      "Epoch 3/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1366 - val_loss: 0.1324\n",
      "Epoch 4/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1299 - val_loss: 0.1264\n",
      "Epoch 5/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1253 - val_loss: 0.1225\n",
      "Epoch 6/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1224 - val_loss: 0.1215\n",
      "Epoch 7/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1197 - val_loss: 0.1212\n",
      "Epoch 8/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1178 - val_loss: 0.1138\n",
      "Epoch 9/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1165 - val_loss: 0.1129\n",
      "Epoch 10/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1151 - val_loss: 0.1121\n",
      "Epoch 11/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1137 - val_loss: 0.1126\n",
      "Epoch 12/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1126 - val_loss: 0.1095\n",
      "Epoch 13/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1115 - val_loss: 0.1088\n",
      "Epoch 14/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1107 - val_loss: 0.1104\n",
      "Epoch 15/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1097 - val_loss: 0.1075\n",
      "Epoch 16/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1090 - val_loss: 0.1094\n",
      "Epoch 17/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1081 - val_loss: 0.1114\n",
      "Epoch 18/50\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1077 - val_loss: 0.1074\n",
      "Epoch 19/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1071 - val_loss: 0.1051\n",
      "Epoch 20/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1067 - val_loss: 0.1059\n",
      "Epoch 21/50\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1062 - val_loss: 0.1029\n",
      "Epoch 22/50\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1058 - val_loss: 0.1040\n",
      "Epoch 23/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1052 - val_loss: 0.1041\n",
      "Epoch 24/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1047 - val_loss: 0.1041\n",
      "Epoch 25/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1042 - val_loss: 0.1045\n",
      "Epoch 26/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1038 - val_loss: 0.1028\n",
      "Epoch 27/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1036 - val_loss: 0.1047\n",
      "Epoch 28/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1033 - val_loss: 0.0999\n",
      "Epoch 29/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1030 - val_loss: 0.1023\n",
      "Epoch 30/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1027 - val_loss: 0.1024\n",
      "Epoch 31/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1023 - val_loss: 0.1057\n",
      "Epoch 32/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1022 - val_loss: 0.1023\n",
      "Epoch 33/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1020 - val_loss: 0.1007\n",
      "Epoch 34/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1016 - val_loss: 0.1018\n",
      "Epoch 35/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1017 - val_loss: 0.1011\n",
      "Epoch 36/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1016 - val_loss: 0.1007\n",
      "Epoch 37/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1016 - val_loss: 0.1015\n",
      "Epoch 38/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1013 - val_loss: 0.1005\n",
      "Epoch 39/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1011 - val_loss: 0.1026\n",
      "Epoch 40/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1007 - val_loss: 0.0987\n",
      "Epoch 41/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1005 - val_loss: 0.1026\n",
      "Epoch 42/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1006 - val_loss: 0.0994\n",
      "Epoch 43/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1001 - val_loss: 0.1010\n",
      "Epoch 44/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1001 - val_loss: 0.0980\n",
      "Epoch 45/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0998 - val_loss: 0.1004\n",
      "Epoch 46/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0997 - val_loss: 0.0976\n",
      "Epoch 47/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0998 - val_loss: 0.1000\n",
      "Epoch 48/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0995 - val_loss: 0.1023\n",
      "Epoch 49/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0993 - val_loss: 0.0995\n",
      "Epoch 50/50\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.0991 - val_loss: 0.0959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x22c3d33fbc8>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "decoded_imgs = autoencoder.predict(x_test)\n",
    "\n",
    "n = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n+1)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Deep CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 134s 2ms/step - loss: 0.1618 - accuracy: 0.9567 - val_loss: 0.0699 - val_accuracy: 0.9802\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 138s 2ms/step - loss: 0.0584 - accuracy: 0.9824 - val_loss: 0.0674 - val_accuracy: 0.9804\n",
      "Epoch 3/3\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0444 - accuracy: 0.9861 - val_loss: 0.0709 - val_accuracy: 0.9807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1ea00c0a7c8>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#preparing the data for training\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#create sequential\n",
    "model = models.Sequential()\n",
    "#add layers\n",
    "model.add(layers.Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(layers.Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(layers.Conv2D(16, kernel_size=3, activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 239us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07086436897389357, 0.9807000160217285]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import img_to_array, array_to_img\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#resizing the images to fit min size of resnet\n",
    "X_train = X_train.reshape(60000,28,28,1)\n",
    "X_test = X_test.reshape(10000,28,28,1)\n",
    "X_train = np.concatenate([X_train]*3, axis = -1)\n",
    "X_test = np.concatenate([X_test]*3, axis = -1)\n",
    "X_train = np.asarray([img_to_array(array_to_img(im, scale=False).resize((32, 32)))for im in X_train])\n",
    "X_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((32, 32)))for im in X_test])\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/3\n",
      "60000/60000 [==============================] - 2671s 45ms/step - loss: 0.4268 - accuracy: 0.9130 - val_loss: 0.5374 - val_accuracy: 0.8460\n",
      "Epoch 2/3\n",
      "60000/60000 [==============================] - 2657s 44ms/step - loss: 0.2647 - accuracy: 0.9452 - val_loss: 0.0772 - val_accuracy: 0.9760\n",
      "Epoch 3/3\n",
      " 1600/60000 [..............................] - ETA: 40:05 - loss: 0.1240 - accuracy: 0.9669"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-b922398ec587>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mres_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#train the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mres_Model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\conda\\envs\\PythonCPU\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#calling the resnet model\n",
    "keras_layer = keras.applications.resnet.ResNet50(\n",
    "    include_top=False, weights='imagenet', input_tensor=None, input_shape=(32,32,3), pooling=None, classes=10\n",
    ")\n",
    "res_Model = models.Sequential()\n",
    "res_Model.add(keras_layer)\n",
    "res_Model.add(layers.Flatten())\n",
    "res_Model.add(layers.Dense(10, activation='softmax'))\n",
    "res_Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#train the model\n",
    "res_Model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 26s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07220974480733275, 0.9782999753952026]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_Model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id                                              tweet   k1   k2   k3   k4  \\\n",
      "0   1                Jazz for a Rainy Afternoon:  {link}  0.0  0.0  0.0  0.0   \n",
      "1   2                   RT: @mention: I love rainy days.  0.0  0.0  0.0  0.0   \n",
      "2   3  Good Morning Chicago! Time to kick the Windy C...  0.0  0.0  0.0  0.0   \n",
      "3   6  Preach lol! :) RT @mention: #alliwantis this t...  0.0  0.0  0.0  0.0   \n",
      "4   9                     @mention good morning sunshine  0.0  0.0  0.0  0.0   \n",
      "\n",
      "    k5   k6     k7   k8     k9  k10  k11  k12    k13  k14  k15  \n",
      "0  0.0  0.0  0.000  0.0  0.000  1.0  0.0  0.0  0.000  0.0  0.0  \n",
      "1  0.0  0.0  0.000  0.0  0.000  1.0  0.0  0.0  0.000  0.0  0.0  \n",
      "2  0.0  0.0  1.000  0.0  0.000  0.0  0.0  0.0  0.000  0.0  0.0  \n",
      "3  0.0  0.0  0.604  0.0  0.196  0.0  0.0  0.0  0.201  0.0  0.0  \n",
      "4  0.0  0.0  0.000  0.0  0.000  0.0  0.0  0.0  1.000  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('twitter-data/tweets_with_labels.csv', sep='\\t')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  Jazz for a Rainy Afternoon:  {link}\n",
      "1                     RT: @mention: I love rainy days.\n",
      "2    Good Morning Chicago! Time to kick the Windy C...\n",
      "3    Preach lol! :) RT @mention: #alliwantis this t...\n",
      "4                       @mention good morning sunshine\n",
      "Name: tweet, dtype: object\n",
      "    k1   k2   k3   k4   k5   k6     k7   k8     k9  k10  k11  k12    k13  k14  \\\n",
      "0  0.0  0.0  0.0  0.0  0.0  0.0  0.000  0.0  0.000  1.0  0.0  0.0  0.000  0.0   \n",
      "1  0.0  0.0  0.0  0.0  0.0  0.0  0.000  0.0  0.000  1.0  0.0  0.0  0.000  0.0   \n",
      "2  0.0  0.0  0.0  0.0  0.0  0.0  1.000  0.0  0.000  0.0  0.0  0.0  0.000  0.0   \n",
      "3  0.0  0.0  0.0  0.0  0.0  0.0  0.604  0.0  0.196  0.0  0.0  0.0  0.201  0.0   \n",
      "4  0.0  0.0  0.0  0.0  0.0  0.0  0.000  0.0  0.000  0.0  0.0  0.0  1.000  0.0   \n",
      "\n",
      "   k15  \n",
      "0  0.0  \n",
      "1  0.0  \n",
      "2  0.0  \n",
      "3  0.0  \n",
      "4  0.0  \n"
     ]
    }
   ],
   "source": [
    "X=df['tweet']\n",
    "y=df.iloc[:, 2:17]\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0            [Jazz, for, a, Rainy, Afternoon:, {link}]\n",
      "1              [RT:, @mention:, I, love, rainy, days.]\n",
      "2    [Good, Morning, Chicago!, Time, to, kick, the,...\n",
      "3    [Preach, lol!, :), RT, @mention:, #alliwantis,...\n",
      "4                  [@mention, good, morning, sunshine]\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#divid x by space\n",
    "length = X.size\n",
    "val =[]\n",
    "for i in range(length):\n",
    "    val.append(X[i].split())\n",
    "X.update(pd.Series(val))\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def det_len(X):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PythonCPU] *",
   "language": "python",
   "name": "conda-env-PythonCPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
